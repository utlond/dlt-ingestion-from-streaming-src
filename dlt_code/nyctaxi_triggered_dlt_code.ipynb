{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba1b16da-906b-43ce-8e88-af9830940d2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "import pyspark.sql.functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3a2517e-d1c5-4b92-a99d-ab339c9ab295",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    comment = \"Loading the latest batch from the continuous dlt pipeline into a staging table\",\n",
    "    name = \"nyctaxidata_latest_batch_of_ingested_trips_stg\",\n",
    "    temporary = False\n",
    ")\n",
    "\n",
    "def load_dlt_ingested_data():\n",
    "\n",
    "    enhanced_trips_df = (\n",
    "        spark.readStream\n",
    "        .format(\"delta\")\n",
    "        .table(\"nyctaxi_dlt.nyctaxidata_ingested_from_trips_src\")\n",
    "    )\n",
    "    \n",
    "    return enhanced_trips_df\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nyctaxi_triggered_dlt_code",
   "notebookOrigID": 2886258870858586,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a4fd26c-d104-43f1-ac3f-99e8532a3ded",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "import pyspark.sql.functions as sf\n",
    "import numpy as np\n",
    "from pyspark.sql.window import Window\n",
    "import math\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bd35ffd-f62b-4738-a7ec-f384048af88f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_by_zip_codes(\n",
    "    trips_df: DataFrame,\n",
    "    bin_size: int\n",
    ") -> DataFrame:\n",
    "\n",
    "    min_max_pu_zip_df = (\n",
    "        trips_df\n",
    "        .select(\n",
    "            sf.min(sf.col(\"pickup_zip\")).alias(\"min_pu_zip\"),\n",
    "            sf.max(sf.col(\"pickup_zip\")).alias(\"max_pu_zip\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get the minimum pickup_zip from the table into a number variable, and floor it to the nearest thousand.\n",
    "    min_pu_zip = [\n",
    "        i[0] for i in \n",
    "        min_max_pu_zip_df.select(\"min_pu_zip\").collect()\n",
    "    ][0]\n",
    "\n",
    "    min_pu_zip = math.floor(min_pu_zip / 1000) * 1000\n",
    "\n",
    "    # Get the maximum pickup_zip from the table into a number variable, and round it up to the nearest thousand.\n",
    "    max_pu_zip = [\n",
    "        i[0] for i in \n",
    "        min_max_pu_zip_df.select(\"max_pu_zip\").collect()\n",
    "    ][0]\n",
    "\n",
    "    max_pu_zip = math.ceil(max_pu_zip / 1000) * 1000\n",
    "\n",
    "    split_list = [float(i) for i in np.arange(min_pu_zip, max_pu_zip + bin_size, bin_size)]\n",
    "\n",
    "    # The \"buckets\" column gives the bucket rank, not the actual bucket value(range).\n",
    "    # Use dictionary to match bucket rank and bucket value.\n",
    "    bucket_names = dict(zip([float(i) for i in range(len(split_list[1:]))], split_list[1:]))\n",
    "    # User defined function to update the data frame with the bucket value\n",
    "    udf_foo = udf(lambda x: bucket_names[x], DoubleType())\n",
    "\n",
    "    bucketizer = Bucketizer(\n",
    "        splits = split_list, \n",
    "        inputCol = \"pickup_zip\", \n",
    "        outputCol = \"pu_zip_ranks\"\n",
    "    )\n",
    "\n",
    "    pu_ranks_df = (\n",
    "        bucketizer\n",
    "        .setHandleInvalid(\"keep\")\n",
    "        .transform(trips_df.select(\"pickup_zip\").dropna())\n",
    "        .dropDuplicates()\n",
    "        .withColumn(\"zip_bins\", udf_foo(\"pu_zip_ranks\"))\n",
    "    )\n",
    "\n",
    "    trips_df_zip_ranks = (\n",
    "        trips_df.alias(\"lt\")\n",
    "        .join(\n",
    "            pu_ranks_df.alias(\"rt\"),\n",
    "            [sf.col(\"lt.pickup_zip\") == sf.col(\"rt.pickup_zip\")],\n",
    "            \"leftouter\"\n",
    "        )\n",
    "        .select(\n",
    "            sf.col(\"lt.*\"), sf.col(\"rt.pu_zip_ranks\"), sf.col(\"rt.zip_bins\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    win = Window.partitionBy(sf.col(\"pu_zip_ranks\"))\n",
    "\n",
    "    trips_df_agg = (\n",
    "        trips_df_zip_ranks\n",
    "        .withColumn(\"trip_count\", sf.count(sf.col(\"pu_zip_ranks\")).over(win))\n",
    "        .withColumn(\n",
    "            \"avg_duration_mins\", \n",
    "            sf.round(sf.avg(sf.col(\"trip_duration_mins\")).over(win))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"zip_bin_lower_bound\",\n",
    "            sf.col(\"zip_bins\") - bin_size\n",
    "        )\n",
    "        .withColumn(\"zip_bin_upper_bound\", sf.col(\"zip_bins\"))\n",
    "        .drop(\"zip_bins\")\n",
    "    )\n",
    "\n",
    "    return trips_df_agg"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "function_definitions",
   "notebookOrigID": 1742547772003629,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
